import shutil

include: "rules/common.smk"

paths = build_paths()
GENOMES = get_samples(paths)

BIG_ENV, BIG_COMMAND = get_bigscape_env()

# Copy the config file into the log directory
paths["LOG_DIR"].mkdir(parents=True)
shutil.copy(workflow.configfiles[0], paths["LOG_DIR"] / "input_config.yaml")

rule all:
    input:
        get_inputs_for_all(paths)


# TODO: gff support
rule run_antismash:
    input:
        genomes = f"{paths['IN_DIR']}/{{GENOMES}}.{config['in_ext']}",
    params:
        antismash = config["antismash_command"],
        antismash_flags = config["antismash_flags"],
        reuse = "--reuse-results" if config["antismash_reuse_results"] else "",
        fail_log = paths['LOG_DIR'] / "antismash_errors.log",
        accept_failure = config['antismash_accept_failure']
    output:
        out_dir = directory(f"{paths['AS_DIR']}/{{GENOMES}}"),
        out_gbk = f"{paths['AS_DIR']}/{{GENOMES}}/{{GENOMES}}.gbk"  # Ensure the run finishes
    conda: config["antismash_conda_env_name"]
    log: paths['LOG_DIR'] / "antismash" / f"{{GENOMES}}.log"
    shell:
        """
        touch {params.fail_log}
        function prepend() {{ while read line; do echo "${{1}}${{line}}"; done; }}
        if {{ asout=$({params.antismash} --output-dir {output.out_dir} -c 1 \
                {params.antismash_flags} {params.reuse} {input.genomes} \
                --logfile {log} 2>&1 \
                | prepend "{wildcards.GENOMES}\t" \
                | tee /dev/fd/3 | \
                sed -n 's/.*ERROR//p'); }} 3>&1
        then
            :
        else
            echo "{wildcards.GENOMES}\t{input.genomes}\t$asout" >> {params.fail_log}
            if {params.accept_failure}; then
                mkdir -p {output.out_dir}
                touch {output.out_gbk}
            else
                exit 1
            fi
        fi
        """

rule tabulate_regions:
    input: expand(f"{paths['AS_DIR']}/{{genomes}}/{{genomes}}.gbk", genomes = GENOMES)
    params:
        script = paths["TABULATE"],
        asdir = paths['AS_DIR']
    output: f"{paths['OUT_DIR']}/all_regions.tsv"
    shell: "python {params.script} {params.asdir} {output}"

rule count_regions:
    input: expand(f"{paths['AS_DIR']}/{{genomes}}/{{genomes}}.gbk", genomes = GENOMES)
    params:
        script = paths["COUNT"],
        asdir = paths['AS_DIR'],
        contig = "--by_contig" if config["count_per_contig"] else "",
        hybrid = "--hybrid" if config["split_hybrids"] else ""
    output: f"{paths['OUT_DIR']}/region_counts.tsv"
    shell: "python {params.script} {params.asdir} {output} {params.contig} {params.hybrid}"


## BiG-SCAPE rules

if config["run_bigscape"]:
    rule run_bigscape:
        input: expand(f"{paths['AS_DIR']}/{{genomes}}/{{genomes}}.gbk", genomes = GENOMES)
        params:
            asdir = paths['AS_DIR'],
            outdir = paths['BIG_DIR'],
            pfam_dir = paths['PFAM_DIR'],
            bigscape_command = BIG_COMMAND,
            bigscape_flags = config['bigscape_flags']
        output:
            directory(f"{paths['BIG_DIR']}"),
            f"{paths['BIG_DIR']}/index.html"
        conda: BIG_ENV
        shell: "{params.bigscape_command} -i {params.asdir} -o {params.outdir}"
                " --pfam_dir {params.pfam_dir} {params.bigscape_flags}"

    rule tar_bigscape:
        input: f"{paths['BIG_DIR']}/index.html"
        params: paths['BIG_DIR']
        output: f"{paths['BIG_DIR']}.tar.gz"
        shell: "tar --exclude 'cache' -zcf {output} -C {params} ."
